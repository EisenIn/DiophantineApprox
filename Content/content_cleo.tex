
\documentclass[a4paper,11pt,american]{article} 
 


\usepackage[utf8]{inputenc} 
%\usepackage{utf8math}

%\usepackage[euler-digits,euler-hat-accent]{eulervm}
\usepackage[boldsans]{concmath}

\usepackage{mathrsfs}
\usepackage[american]{babel}
\usepackage{mathtools} % includes amsmath
\usepackage{tikz}
\usepackage{quiver}
\usepackage{amssymb}
\usepackage{amscd}
\usepackage{todonotes}

\usepackage{amsthm}

%\usepackage{multirow}
\usepackage{enumerate}

%\usepackage{tikz}
\usepackage{framed}
%\usepackage[colorlinks]{hyperref}
%\usepackage{showlabels}  


\newcommand{\smat}[1]{ \big(\begin{smallmatrix} #1 \end{smallmatrix}\big)}

\newcommand{\E}{\mathbb{E}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\X}{\mathscr{X}}
\newcommand{\cA}{\mathcal{A}}
\newcommand{\cD}{\mathcal{D}}
\newcommand{\cO}{\mathcal{O}}
\newcommand{\cI}{\mathcal{I}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cV}{\mathcal{V}}
\newcommand{\pscal}[1]{\langle {#1} \rangle}
\newcommand{\wt}[1]{\widetilde{#1}}
\newcommand{\car}{\mathrm{Char}}



\providecommand{\one}{\mathbf{1}}
\DeclareMathOperator{\vol}{vol}
\DeclareMathOperator{\rank}{rang}
\DeclareMathOperator{\noy}{noyau}
\DeclareMathOperator{\cone}{cone}
\DeclareMathOperator{\tcone}{tcone}
\DeclareMathOperator{\SV}{SV}
\DeclareMathOperator{\conv}{conv}
\DeclareMathOperator{\spec}{spec}
\DeclareMathOperator{\cof}{cof}
\DeclareMathOperator{\diam}{diam}
\DeclareMathOperator{\sign}{sgn}
\DeclareMathOperator{\poly}{poly}
\DeclareMathOperator{\Ker}{Ker}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\relint}{relint}
\DeclareMathOperator{\spa}{span}
\DeclareMathOperator{\Tr}{Tr}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\pspace}{\mathcal{PSPACE}}
\DeclarePairedDelimiter\mnorm{\lvert\lvert\lvert}{\rvert\rvert\rvert} % matrix norm



\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}

\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem*{notation}{Notation}
\newtheorem{example}{Exemple}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{problem}{Problem}

\newtheorem{exercise}{Exercise}
\newtheorem{algorithm}{Algorithm}

\setlength{\parindent}{0pt}  % No indents 

\newcommand{\iunit}{\mathrm{i}}
\newcommand{\CC}{{\mathbb C}}
\newcommand{\EE}{{\mathbb E}}
\newcommand{\FF}{{\mathbb F}}
\newcommand{\KK}{{\mathbb K}}
\newcommand{\NN}{{\mathbb N}}
\newcommand{\QQ}{{\mathbb Q}}
\newcommand{\RR}{{\mathbb R}}
\newcommand{\ZZ}{{\mathbb Z}}

\newcommand{\calB}{{\mathcal B}}


%opening

\title{Diophantine Approximation}
\author{Friedrich Eisenbrand}

\begin{document}


\maketitle



\subsection*{22. September 2023}

Motivation for the neeed for approximation by rationals with small denominator: Calendar design.

Let $\alpha\in\R$. A fraction $(p/q)$ with $p,q\in \Z$ and $q\geq 1$ is a \emph{best approximation} of $\alpha$ if for each fraction $c/d \neq p/q$  with $c,d \in\Z$ and $d\geq1$ one has:
\begin{displaymath}
  0 < d \leq q \text{ implies } \vert \alpha - p/q \vert < \vert\alpha - c/d \vert. 
\end{displaymath}

\emph{Rounding with denominator bound}: Given $\alpha\in\R$ and $N \in \N_+$, find $(p/q)$ with $1\leq q \leq N$ and  $\vert \alpha - p/q\vert $ minimal.\\\\
\emph{Notations}: For $x\in \R$ we note:
\begin{displaymath}
    \lfloor x\rfloor=\max\{z\in\N:z\leq x\},\text{and}\;
    \lceil x\rceil=\min\{z\in\N:z\geq x\}
\end{displaymath}
We define the \emph{fractionnal part} of $x$ as follows:
\begin{displaymath}
    \{x\}=x-\lfloor x\rfloor
\end{displaymath}
\emph{Notations}: For $x\in \R$ we note:
\begin{displaymath}
    \lfloor x\rceil=\lfloor x\rfloor\;\text{if}\; \{x\}\leq 1/2\; \text{and}\; \lceil x\rceil\; \text{otherwise}
\end{displaymath}
\emph{Simple $N$-rounding}: Approximate $\alpha$ with $ \lfloor N \cdot \alpha \rceil / N$. With this type of approximation we get that $\vert \alpha-\frac{\lfloor \alpha\cdot N\rceil}{N}\vert \leq\frac{1}{2N}$.\\\\
\emph{Remark} We cannot get a much better bound:\\
Let $\alpha\in \R\backslash\Q$ we then it exists $z\in \Z$ such that $\alpha=\frac{N\cdot z +\frac{1}{2}-\epsilon}{N}$. Hence simple rounding gives us an error of $\frac{\frac{1}{2}-\epsilon}{N}$
\begin{theorem}[Dirichlet]
  \label{thr:1}
  Let  $\alpha\in \R$ and  $N \in \N_+$. There exists a fraction $p/q$ with $p,q\in\Z $ such that
  \begin{enumerate}[i)]
  \item $1 \leq q \leq N$, and
  \item $\vert \alpha - p/q\vert < 1/(q\cdot N)$ 
  \end{enumerate}
\end{theorem}
  This is much better than $1/(2N)$ as soon as $q$ gets larger. The more you \emph{pay} for the denominator $q$, the better the approximation is.

  \begin{proof}[Proof of Dirichlet's Theorem] 
    For $0 \leq q \leq N$ consider the points $\{q \cdot\alpha\}$. These points lie in $[0,1)$ and there are $N+1$ many of them. This means that two of them are at a distance of strictly less than $1/N$ from each other. Therefore, there exist $q_1,q_2 \in \{0,\dots,N\}$ such that $\vert\{q_1 \cdot\alpha\} -\{q_2 \cdot \alpha\} \vert < 1/N$. Since $\{q_i \cdot\alpha\} = q_i \cdot\alpha - x_i$  for some suitable $x_i \in\Z$ we have:
    \begin{displaymath}
          \vert (q_1 -q_2)\cdot\alpha - (x_1-x_2) \vert < 1/N.
    \end{displaymath}
    Now we can just set $q= q_1-q_2 \in \{1,\dots,N\}$ and $p=x_2-x_1$
  \end{proof}
  
Reading: \cite{eisenbrand2012pope,WikiDirichlet}  


\subsection*{29. September 2023}

%Reading: The book of Khinchine~\cite[Section~2]{khinchin1997continued}.
\emph{Best Approximation Geometric algorithm}\\
Let $\alpha\in\R_{>0}$ and $N\in \N_+$. We want to find $(p,q)\in(\N\times\N_+)$ such that $\vert \alpha-p/q\vert$ is minimal among all such duples $(r,s)$ with $s\leq N$.\\
\emph{ ALgorithm}: First take $V_1=(0,1)$, $V_2=(1,0)$ a basis of $\Z^2$.\\
Secondly we add $\lambda\in \N$ times the vector $V_1$ to $V_2$ where $\lambda$ is the biggest integer such that $V_2+\lambda V_1$ does not cross the line passing through $0$ with slope $\alpha$. We obtain a new basis $V_1,V_3=V_2+\lambda V_1$.\\
Now for the iteration step :
\begin{enumerate}
    \item Add the longer vector ($V_i$) to the shorter one ($V_j$) until the last moment such that the sum.
    \begin{enumerate}[i)]
    \item does not cross the line
    \item \label{ii} does not cross the vertical denominator
\end{enumerate}
\item Create your new basis $\{V_i,V_j+\lambda V_i\}$.
\end{enumerate}
%Explain the geometric intuition behind the theory of continued fractions, as in \cite{eisenbrand2012pope}.\\ 
Here is an example of this algorithm:
\[\begin{tikzcd}
	&&&&&& {} & {} \\
	{} &&&&&& \bullet \\
	&&&&&& {} \\
	{} && \bullet && \bullet \\
	\\
	\bullet & {} & {} && {} && {}
	\arrow[""{name=0, anchor=center, inner sep=0}, from=6-1, to=2-1]
	\arrow[color={rgb,255:red,0;green,8;blue,235}, from=4-1, to=4-3]
	\arrow["{V_1}"', color={rgb,255:red,0;green,8;blue,235}, from=6-1, to=6-3]
	\arrow["{V_3=V_1+V_2}"{pos=0.6}, color={rgb,255:red,255;green,51;blue,235}, from=6-1, to=4-3]
	\arrow[color={rgb,255:red,255;green,51;blue,235}, from=6-3, to=4-5]
	\arrow[color={rgb,255:red,255;green,51;blue,235}, from=4-5, to=2-7]
	\arrow["{\text{line through 0 with slope}\; \alpha}"{pos=0.7}, color={rgb,255:red,233;green,1;blue,17}, no head, from=6-1, to=1-8]
	\arrow["{V_4=V_1+2V_3}"'{pos=0.2}, color={rgb,255:red,79;green,79;blue,227}, from=6-1, to=2-7]
	\arrow[from=6-1, to=6-5]
	\arrow["{\text{Bound}\; N}", color={rgb,255:red,233;green,1;blue,17}, no head, from=1-7, to=6-7]
	\arrow["{V_2}", color={rgb,255:red,4;green,169;blue,4}, from=6-1, to=0]
\end{tikzcd}\]
\emph{Observation}\begin{itemize}
    \item The algorithm only stops when $V_1+V_2$ cross the denominator bound.
    \item The vectors $V_i,V_j$ remain positive in both components.
    \item The second component has an exponential growth, hence after $\log(N)$ iteration the algorithm stops.
\end{itemize}
\emph{Upon termination} take the longer verctor of your basis : $V_i=(p,q)$, then $(p,q)$ is a solution to the problem.
\begin{proof}
    Suppose that $\frac{r}{s}$ is a better approximation to $\alpha$ than $\frac{p}{q}$ and let $V_1,V_2$ the last basis obtained by the algorithm. Then $(r,s)=x_1\cdot V_1+ x_2\cdot V_2$ with $x_1,x_2\in\Z$. In particular as $\frac{r}{s}$ is a better approximation than $(p,q)$ then $(r,s)$ is contained in the cone generated by $V_1,V_2$ so $x_1,x_2\in \N_+$. Therefore $s\geq V_{1_2}+V_{2_2}$, hence $s>N$ by definition of the algorithm. 
\end{proof}
Explain  continued fraction expansion of a number $\alpha\in\R\backslash \Q$:

$\alpha =  \lfloor\alpha\rfloor + \{\alpha\}=\frac{1}{\frac{1}{\{\alpha\}}} $. Setting $\beta = \frac{1}{\{\alpha\}}$:
 
  \begin{displaymath}
    \alpha = \lfloor\alpha\rfloor + \cfrac{1}{ \lfloor\beta\rfloor + \cfrac{1}{\lfloor\gamma\rfloor+ \dots}} 
  \end{displaymath}

  Process does not end. If $\alpha \in\Q$, process ends. Mention relation to Euclidean algorithm.

  Explain continued fraction expansion of $\sqrt{2}$.\\
\emph{Example}: The continued fractio expansion of $\sqrt{2}$:\begin{align*}
    \sqrt{2}&=1+(\sqrt{2}-1)=1+(\sqrt{2}-1)\dfrac{(\sqrt{2}+1)}{(\sqrt{2}+1)}\\
    &=1+\dfrac{1}{1+\sqrt{2}}=1+\cfrac{1}{1+(1+\cfrac{1}{1+\sqrt{2}})}\\
    &=1+\cfrac{1}{2+\cfrac{1}{1+\sqrt{2}}}=1+\cfrac{1}{2+\cfrac{1}{2+\cfrac{1}{2+\cfrac{1}{...}}}}
\end{align*}

  \begin{definition}
    For $a_0 \in \R$ and $a_1,\dots,a_n \in\N_+$ write
    \begin{equation}      
      [a_0;a_1,\dots,a_n] = a_0 + \cfrac{1}{a_1 + \cfrac{1}{a_2 + \cfrac{1}{\cdots  \cfrac{1}{a_n}}}}
      \label{eq:1}
    \end{equation}
  \end{definition}
The equation~\eqref{eq:1} is a fraction $p_n / q_n$ that depends on the sequence $a_0,\dots,a_n$.


\begin{theorem}
  \label{thr:2}
  Set $p_{-1} = 1, q_{-1} = 0, p_{-2} = 0, q_{-2} =1$. Then for $k\geq1$ one has $[a_0;a_1,\dots,a_k]=\frac{p_k}{q_k}$ with
  \begin{equation}
    \label{eq:2}
    \begin{array}{rcl}
    p_ k & = & p_{k-1} a_k + p_{k-2}\\
      q_ k & = & q_{k-1} a_k + q_{k-2}.
    \end{array}
  \end{equation}
  
\end{theorem}
  \begin{proof}
      For $k=0$ we have $a_0=\frac{a_0}{1}=\frac{p_0}{q_0}$.\\
      Let $k>0$ and suppose the theorem is true for $k-1$. By definition of $[a_0;a_1,\dots,a_k]$ we have that $[a_0;a_1,\dots,a_k]=[a_0;a_1,\dots,a_{k-1}+\frac{1}{a_k}]$. By induction hypothesis we then obtain that \begin{align*}
          \frac{p_k}{q_k}=\frac{\Tilde{p}_{k-1}}{\Tilde{q}_{k-1}}&=\frac{p_{k-2}(a_{k-1}+\frac{1}{a_k}) + p_{k-3}}{q_{k-2} (a_{k-1}+\frac{1}{a_k}) + q_{k-3}}\\
          &=\frac{p_{k-2} a_{k-1} + p_{k-3}+\frac{p_{k-2}}{a_k}}{q_{k-2} a_{k-1} + q_{k-3}+\frac{q_{k-2}}{a_k}}\\
          &=\frac{p_{k-1}+\frac{p_{k-2}}{a_k}}{q_{k-1}+\frac{q_{k-2}}{a_k}}=\frac{p_{k-1} a_k + p_{k-2}}{q_{k-1} a_k + q_{k-2}}
      \end{align*}
  \end{proof}
This theorem gives a recursive formula to compute the value of~\eqref{eq:1}. In matrix notation one has
\begin{equation}
  \label{eq:3}
  \begin{pmatrix}
    p_k & p_{k-1} \\
    q_k & q_{k-1}
  \end{pmatrix} =
  \begin{pmatrix}
    a_0 & 1\\
    1 & 0
  \end{pmatrix} \cdots
  \begin{pmatrix}
    a_k & 1 \\
    1 & 0
  \end{pmatrix}
\end{equation}



\begin{theorem}
  \label{thr:3}
  For $k\geq -1$ one has
  \begin{displaymath}
    p_k q_{k-1} - q_k p_{k-1} = (-1)^{k+1} 
  \end{displaymath}
\end{theorem}
\begin{proof}
    By $\eqref{eq:3}$ we obtain that $\det(\begin{pmatrix}
    p_k & p_{k-1} \\
    q_k & q_{k-1}
  \end{pmatrix})=(-1)^{k+1}$
\end{proof}
Observation: If $a_i \in\N_+$ for $i\geq1$ and $a_0 \in\Z$, then $\gcd(p_k,q_k) = 1$.
\begin{corollary}
  \label{co:1}
  \begin{equation}
    \label{eq:4}
      \frac{p_{k-1}}{q_{k-1}} - \frac{p_k}{q_k} = \frac{(-1)^k }{q_k q_{k-1}}.    
  \end{equation}

\end{corollary}

\begin{theorem}
  For all $k\geq 1$:
  \begin{displaymath}
    q_k p_{k-2} - p_k q_{k-2} = (-1)^ {k+1} a_k. 
  \end{displaymath}
\end{theorem}
\begin{proof}
    From $\eqref{eq:2}$ we obtain \begin{equation}
        \label{eq:5}\begin{array}{rcl}
         p_ kq_{k-2} &=&  p_{k-1} a_kq_{k-2} + p_{k-2}q_{k-2}\\
        q_ kp_{k-2}  &=& q_{k-1} a_kp_{k-2} + q_{k-2}p_{k-2}
        \end{array}
    \end{equation}
    Substracting those two equations we obtain that 
    $$ p_ kq_{k-2}-q_ kp_{k-2}=(p_{k-1}q_{k-2}-q_{k-1}p_{k-2})a_k$$
    It follows from theorem \eqref{thr:3} the equality become $q_k p_{k-2} - p_k q_{k-2} = (-1)^ {k+1} a_k$
\end{proof}

\begin{corollary}
  \label{co:2}
  For all $k\geq 2$:

  \begin{displaymath}
    \frac{p_{k-2}}{q_{k-2}} -    \frac{p_k}{q_k} = \frac{(-1)^{k-1} a_k}{q_k q_{k-2}}. 
  \end{displaymath}
\end{corollary}

We always assume $a_0\in\Z$ and $a_i \in \N_+$ for $i\geq1$.





\subsubsection*{Convergence of convergents}

Then Corollary~\ref{co:2} implies that even convergents are increasing sequence and off convergents are decreasing. Together with Corollary~\ref{co:1} and the exponential growth of the sequence $p_k$ we have fast convergence of the convergents.



\subsection*{6. October 2023}
\begin{lemma}\label{lem:7}
Let $\alpha\in\R\backslash\Q$ and $f(x)=[a_0;a_1,\dots,a_{k-1},x]$.\\
For $k$ even: $f(x)$ is increasing and $a_k\in \N_+$ is the largest integer such that \begin{equation}
    [a_0;a_1,\dots,a_k]<\alpha
\end{equation}
For $k$ odd: $f(x)$ is decreasing and $a_k\in \N_+$ is the largest integer such that \begin{equation}
    [a_0;a_1,\dots,a_k]>\alpha
\end{equation}
\end{lemma}
\begin{proof}
    Developp a recursive argument with $\alpha=a_0+\cfrac{1}{a_1+\cfrac{1}{[a_2,a_3,\dots]}}$
\end{proof}
\emph{Definition}: We call $[a_0;a_1,\dots,a_k]$ the \emph{k-th convergent} of $\alpha$.
\begin{theorem}\label{th:8}
    Let $a_0\in\Z$ and $\forall i\in\N_+,\; a_i\in\N_+$ then for $k\geq 2$ we have $q_K\geq 2^{\frac{k-1}{2}}$
\end{theorem}
\begin{proof}
    We know from theorem $\eqref{thr:2}$ that $ q_ k =  q_{k-1} a_k + q_{k-2}$ and therefore $ q_ {k-1}  =  q_{k-2} a_{k-1} + q_{k-3}$. It follows that $q_k\geq 2\cdot q_{k-2}$.\\
    So for $k\geq 1$ we obtain that :\begin{itemize}
        \item $q_{2k}\geq 2^k\cdot q_o=2^k$
        \item $q_{2k+1}\geq 2^k\cdot q_1\geq 2^k$
    \end{itemize}
\end{proof}
\begin{theorem}
    Let $\alpha\in\R\backslash\Q$. For $k\geq 1$... 
\end{theorem}
\begin{proof}
    \begin{align}
        \vert\alpha-\frac{p_k}{q_k}\vert&\leq\vert \frac{p_{k-1}}{q_{k-1}}-\frac{p_k}{q_k}\vert \label{eq:8}\\
        &\leq \frac{1}{q_k\cdot q_{k-1}}\label{eq:9}\\
        &\leq \frac{1}{q^{\frac{k-1}{2}\cdot\frac{k-2}{2}}}=\frac{1}{2^k\cdot2^\frac{-3}{2}}=\frac{2^\frac{3}{2}}{2^k}\label{eq:10}
    \end{align}
    Where in $\eqref{eq:8}$ we used lemma $\eqref{lem:7}$, in \eqref{eq:9} we used corollary $\eqref{co:1}$ and in $\eqref{eq:10}$ we used theorem $\eqref{th:8}$.
\end{proof}
\begin{corollary}
    Continued fraction expansions converges exponentially to $\alpha$
\end{corollary}
\begin{theorem}
    Let $\alpha\in\R\backslash\Q$, every best approximation to $\alpha$ is a convergent or intermediate convergente of $\alpha$. In other words it exists $k\geq 0$ such that the best approximation of $\alpha$ is $[a_0,a_1;\dots,a_{k-1},j]$ for $1\leq j\leq a_k$.
\end{theorem}
\begin{proof}
    Suppose it exists a best approximation $\frac{a}{b},\; b\in\N_+$  of $\alpha$ that is not a convergent or an intermediate convergent.\\
    Let $r_1$ be the last convergent with $q_k<b$ i.e $r_1=[a_0,a_1;\dots,a_k]$. Let $r_2$ be the last intermediate convergent of $\alpha$ i.e $r_2=\frac{j\cdot p_k+p_{k-1}}{j\cdot q_k+q_{k-1}}$ with $j$ the biggest integer such that $j\cdot q_k+q_{k-1}\leq b$.\\
    Suppose $k$ is even: therefore we know that $r_1<\alpha<r_2$.\\
    As $\frac{a}{b}$ is a best approximation we have that $\frac{a}{b}\in [r_1,r_2]$ so it follows that 
    \begin{equation}
        \frac{a}{b}-r_1=\frac{a}{b}-\frac{p_k}{q_k}>0\implies \frac{a}{b}-\frac{p_k}{q_k}=\frac{\vert a q_k-b p_k\vert}{b q_k}\geq \frac{1}{bq_k}
    \end{equation}
    \begin{equation}r_2-\frac{a}{b}>0\implies \frac{j\cdot p_k+p_{k-1}}{j\cdot q_k+q_{k-1}}-\frac{a}{b}\geq \frac{1}{b(j\cdot q_k+q_{k-1})}
    \end{equation}
    hence $\dfrac{a}{b}\geq \dfrac{1}{bq_k}$ and $r_2-\dfrac{a}{b}\geq \dfrac{1}{b(j\cdot q_k+q_{k-1})}$. Therefore we obtain that :\begin{align*}
        r_2-r_1&\geq \frac{1}{b}(\frac{1}{(j\cdot q_k+q_{k-1})}\cdot \frac{1}{q_k})\\
        &=\frac{1}{b}(\frac{(j+1)\cdot q_k+q_{k-1}}{q_k(j\cdot q_k+q_{k-1})})\\
    \end{align*}
    By definition of $j$ it follows that $r_2-r_1>\frac{1}{q_k(j\cdot q_k+q_{k-1})}$.
    But at the same time\begin{align*}
        r_2-r_1&= \frac{j\cdot p_k+p_{k-1}}{j\cdot q_k+q_{k-1}}-\frac{p_k}{q_k}=\frac{j\cdot p_kq_k+p_{k-1}q_k-j\cdot q_kp_k-p_kq_{k-1}}{q_k(j\cdot q_k+q_{k-1})}\\
        &=\frac{p_{k-1}q_k-p_kq_{k-1}}{q_k(j\cdot q_k+q_{k-1})}=\frac{-(-1)^{k+1}}{q_k(j\cdot q_k+q_{k-1})}=\frac{1}{q_k(j\cdot q_k+q_{k-1})}
    \end{align*}
    So we obtained a contradiction. The case with $k$ odd is roughly similar.
\end{proof}
\emph{Example} Let $\alpha=\epsilon+\frac{17}{4}$. For $\epsilon$ sufficiently small, the best approximation with denominator bound equal to 3 is $\frac{13}{3}=[4;3]$ and one can compute that $a_1=4$.
%Solution to the best approximation problem.

\subsection*{13. October 2023}

We consider the Diophantine equation
\begin{equation}
  \label{eq:6}
  x^2 - dy^2  = 1, \, x,y \in \Z,
\end{equation}
where $d \in\N $. A trivial solution is $(x,y) = (\pm 1, 0)$.
\begin{exercise}
  \label{exe:1}
  Convince yourself of the fact that, if a non-trivial solution exists, then $d$ is not a perfect square. 
\end{exercise}

We also consider the field $\Q(\sqrt{d}) = \{x+y\sqrt{d}:x,y\in\Q \}$ and  the ring $\Z[ \sqrt{d}] = \{ x+ y \sqrt{d}:x,y \in\Z\}$.
\begin{exercise}
  \label{exe:2}
  Convince yourself that the above are indeed a field and a ring. 
\end{exercise}




The \emph{norm} of an element $x + y \sqrt{d} \in \Q(\sqrt{d})$ is the rational number $(x + y \sqrt{d}) (x - y \sqrt{d} ) = x^2 -d y^2$. It is denoted by $N(x+y\sqrt{d})$. 
\begin{exercise}
  \label{exe:3}
  Show that the norm is multiplicative, i.e. that for $\alpha,\beta \in\Q(\sqrt{d})$ one has $N(\alpha\cdot\beta) = N(\alpha)\cdot N(\beta)$. 
\end{exercise}


If $(x,y) \in\Z^2$ is a solution to~\eqref{eq:6}, then $x + y \sqrt{d}$ is a \emph{unit} in $\Z[ \sqrt{d}]$, since $(x + y \sqrt{d})(x - y \sqrt{d}) =1$. However, not each unit corresponds to a solution of \eqref{eq:6}. For example, $1 - \sqrt{2} \in\Z[\sqrt{2}]$ is  unit, but $1^2 - 2 \cdot 1^2 = -1$. This is a \emph{unit of norm $-1$}.

There is a correspondence between units of norm $1$ and solutions of the Pell equation~\eqref{eq:6}. 



\begin{theorem}
  \label{thr:4}
  If $d \in\N_+$ is not a perfect square, then \eqref{eq:6} has a nontrivial solution. 
\end{theorem}


\begin{proof}
  We recall Dirichlet's Theorem~\ref{thr:1}. This implies that there exist infinitely many pairs $(p,q) \in\N\times\N_+$ with $\gcd(p,q) = 1$ such that 
   \begin{displaymath}
    \vert p - q \sqrt{d}  \vert < 1/q. 
  \end{displaymath}

  For such $(p,q)$ one has, by the triangle inequality also  $ \vert p +  q \sqrt{d}  \vert \leq 1/q + 2 q \sqrt{d} $. By multiplying both inequalities, one obtains
  \begin{displaymath}
    \vert p^2 - d q^2 \vert <  1/q^2 + 2 \sqrt{d} \leq 1 + 2 \sqrt{d},
  \end{displaymath}
  which is a constant. Consequently, there exits a constant $r \in\Z$
  and infinitely many pairs $(p,q) \in(\N\times\N_+)$ with
  \begin{equation}
    \label{eq:7}    
    p^2 - d q^2  = r.
  \end{equation}

  There are only $r^2$ many elements in $\Z_r \times\Z_r$. This implies that
  there exists one such vector $(u,v) \in \Z_r \times\Z_r$ and infinitely many
  pairs $(p,q) \in\N\times\N_+$ with $(p,q) \equiv (u,v) \pmod{r}$ that satisfy
  \eqref{eq:7}.


  Now let   $(p_1,q_1) \neq  (p_2,q_2) \in(\N \times \N_+)$ be two such pairs. We show that
  \begin{equation}
    \label{eq:11}   
  \alpha =  (p_1 + \sqrt{d} q_1 ) (p_2 + \sqrt{d} q_2)^{-1} \in \Z[\sqrt{d}]. 
  \end{equation}
  Since $N(\alpha) = 1$, $\alpha$ is a unit of norm one and if it is non-trivial, we are done, once we have established~\eqref{eq:11}.

  We have
  \begin{displaymath}
    \alpha = \frac{p_1 p_2 - d q_1 q_2}{r} + \frac{-p_1q_2 + q_1p_2}{r} \sqrt{d}.  
  \end{displaymath} 
  Since $p_1 p_2 - d q_1 q_2 \equiv p_1^2 - d q_1^2 \equiv 0\pmod{r}$ and since $-p_1q_2 + q_1p_2 \equiv 0 \pmod{r}$, it follows that $\alpha \in\Z[\sqrt{d}]$.  On the other hand, since $\gcd(p_1,q_1) =\gcd(p_2,q_2)=1$,   $p_1q_2 = q_1p_2$ implies $p_1 = p_2$ and $q_1 = q_2$ which is excluded. Thus $\alpha$ is not rational and this yields a nontrivial solution of~\eqref{eq:6}, namely $x = (p_1 p_2 - d q_1 q_2)/r$ and $y = (-p_1q_2 + q_1p_2)/{r}$. 
\end{proof}

  \subsubsection*{Solving the Pell equation with continued fractions}


  If $d \in \N_+$ is not a perfect square, then $\sqrt{d}$ is irrational. One can compute the continued fraction expansion of $\sqrt{d}$. Recall that one has  \eqref{eq:4} from which we conclude
  \begin{displaymath}
    \vert  \sqrt{d} - p_k / q_k \vert  \leq 1 (q_k q_{k+1}) \leq 1/ q_k^2 
  \end{displaymath}
  and that the fraction $p_k/q_k$ are reduced for $k\geq0$. This means that we can attractively compute solutions $(p_k^2 - d q_k^2) = r$ with $\vert r\vert  \leq 1 + 2 \sqrt{d}$. Once we have computed  $k \geq\lceil  2( 1  + 2\sqrt{d} ) +1 \rceil   \cdot \lceil 1 + 2 \sqrt{d}\rceil ^2 $ convergents,  we can identify two of them that yield $(p_1,q_1)$ and $(p_2,q_2)$ as in the proof of Theorem~\ref{thr:4} and construct a nontrivial solution of $x^2 - d y^2 = 1$. The running time of this naive algorithm is $O(d^{3/2})$  which is polynomial in the \emph{value } of  $d$ but \emph{exponential} in the \emph{binary encoding length} of $d$. It is also known that there exist $d$ such that each nontrivial solution of the Pell equation requires an exponential number of bits in $\ln (d)$, see~\cite{lenstra2002solving}. 


  \begin{example}
    \label{exe:4}

    We want to find a nontrivial solution of
    \begin{displaymath}
      x^2 - 3 y^2 = 1, \, x,y \in\Z. 
    \end{displaymath}
    The continued fraction expansion of $\sqrt{3} = [1; \overline{1,2}]$.    Starting with
    \begin{displaymath}
      \begin{pmatrix}
        p_{-1} & p_{-2}  \\
        q_{-1} & q_{-2}  
      \end{pmatrix}
      =
      \begin{pmatrix}
        1 & 0 \\
        0 & 1
      \end{pmatrix} 
    \end{displaymath}
    we compute
    \begin{displaymath}
      \begin{pmatrix}
        p_{0} & p_{-1}  \\
        q_{0} & q_{-1}  
      \end{pmatrix} =
      \begin{pmatrix}
        1 & 1  \\
        1 & 0  
      \end{pmatrix},
    \end{displaymath}
 \begin{displaymath}
      \begin{pmatrix}
        p_{1} & p_{0}  \\
        q_{1} & q_{0}  
      \end{pmatrix} =
      \begin{pmatrix}
        1 & 1  \\
        1 & 0  
      \end{pmatrix}
       \begin{pmatrix}
        1 & 1  \\
        1 & 0  
      \end{pmatrix}  =
      \begin{pmatrix}
        2 & 1  \\
        1 & 1  
      \end{pmatrix} 
    \end{displaymath}


    \begin{displaymath}
      \begin{pmatrix}
        p_{2} & p_{1}  \\
        q_{2} & q_{1}  
      \end{pmatrix} =
      \begin{pmatrix}
        2 & 1  \\
        1 & 1  
      \end{pmatrix}
       \begin{pmatrix}
        2 & 1  \\
        1 & 0  
      \end{pmatrix}  =
      \begin{pmatrix}
        5 & 2  \\
        3 & 1  
      \end{pmatrix} 
    \end{displaymath}
    and
    
    \begin{displaymath}
      \begin{pmatrix}
        p_{3} & p_{2}  \\
        q_{3} & q_{2}  
      \end{pmatrix} =
      \begin{pmatrix}
        5 & 2  \\
        3 & 1  
      \end{pmatrix}
       \begin{pmatrix}
        1 & 1  \\
        1 & 0  
      \end{pmatrix}  =
      \begin{pmatrix}
        7 & 5  \\
        4 & 3  
      \end{pmatrix}. 
    \end{displaymath}
    We find a non-trivial solution
    \begin{displaymath}
      (x,y) = (7,4)  \in\Z^2
    \end{displaymath}
    $7^2 - 3\cdot 4^2 = 1$. In this example, we did not search for convergents of same value and remainder pattern as in the proof. Instead, we just computed some convergents until we found a solution. We have not argued that  this always works. 
  \end{example}


\subsubsection*{Liouville's Theorem}


A number $\alpha \in\C$ is \emph{algebraic}, if there exist a nonzero polynomial $p(x) \in \Q[x]$ with $p(\alpha) = 0$. The \emph{minimal polynomial} of $\alpha$ is the unique monic nonzero polynomial $p(x) \in\Q[x]$ with $p(\alpha) = 0$. The degree of $\alpha$ is the degree of this polynomial.  By multiplying with the least common multiple of the denominators of the coefficients of $p(x)$, we obtain a polynomial $q(x) \in\Z[x]$ of \emph{content} one, meaning that the greatest common divisor of the coefficients of $q$ is one. One can easily see that there is a unique nonzero polynomial $q(x) \in\Z[x]$ with content one and positive leading coefficient of minimal degree that has $\alpha$ as a root.

\begin{theorem}[Liouville's Theorem]
  \label{thr:5}
  Let $\alpha\in\R$ be algebraic of degree $d\geq2$. There exists a positive constant $c_\alpha \in \R_+$ such that for each $(p,q) \in \Z \times \N_+$ one has
  \begin{displaymath}
    \vert  \alpha - p/q \vert  > c_\alpha 1/q^d. 
  \end{displaymath}
\end{theorem}

\begin{proof}
  Let $(p,q) \in \Z \times\N_+$ such that  $\vert  \alpha - p/q \vert  \leq1$. We only have to consider those. 

  Let $f(x) \in \Z[x]$ be a nonzero polynomial of degree $d$ with $f(\alpha) = 0$.  One has $f(p/q) \neq 0$. Otherwise, $x- p/q$ divides $f$ and we find a polynomial of smaller degree with root $\alpha$. \emph{(Recall $\alpha \neq p/q$!)}.  But $q^d \cdot f(p/q) \in\Z$ from which we infer $q^d \cdot \vert f(p/q)\vert  \geq1$ and therefore 
  \begin{displaymath}
     \vert f(p/q)\vert  \geq1 / q^d. 
   \end{displaymath}
   Both $\alpha$ and $p/q$ are contained in the interval $[\alpha -1, \alpha+1]$. 
  By the mean-value theorem, there exits $x^* \in [\alpha -1, \alpha+1]$ with
  \begin{displaymath}
    \vert f'(x^*)\vert  = \vert f(\alpha) - f(p/q)\vert  / \vert \alpha - p/q\vert  = \vert f(p/q)\vert  / \vert \alpha - p/q\vert  . 
  \end{displaymath}
  Set $\beta = (\sup\{ \vert f'(x)\vert:x \in [\alpha-1 ,\alpha+1]\}$. This is a number bigger than $0$.   Then, by the above, we have 
  \begin{displaymath}
    \beta \geq 1/ ( \vert \alpha - p/q\vert  q^d). 
  \end{displaymath}
  Setting $c_\alpha = 1/ \beta$ we conclude 
  \begin{displaymath}
    \vert \alpha - p/q\vert  \geq c_\alpha / \vert f(p/q)\vert . 
  \end{displaymath}
\end{proof}
\subsection*{20. October 2023}
\begin{theorem}[Mikowski first theorem]\label{Th:mink1}
    Let $A\subseteq\R^2$ with area bigger than 1 then it exists $x,y\in A$ such that $x-y\in \Z$.
\end{theorem}
\begin{proof}
    Divide the plan $\R^2$ in squares of area 1 as in. Now translate every area of A into the square $\{(0;0), (0;1), (1;0),(1;1)\}$. As the Area of A is bigger than 1, by the Pigeon Hole Principle at least 1 point of the square $\{(0;0), (0;1), (1;0),(1;1)\}$ is touched twice. Hence it exists $x,y\in A$ such that there relative positions on there square is the same. In other words $x,y$ are such that $x-y\in \Z$.
\end{proof}
\emph{Remark:} this is also true for $\R^n$ for $n\in \N$.\\
\emph{Recall} A set $A$ is convex if $\forall a,b\in A$ and $\lambda\in \R$ such that $0\leq \lambda\leq1$ we have $\lambda a+(1-\lambda)b\in A$.
\begin{theorem}[Mikowski second theorem]\label{th:mink2}
    Let $A\subseteq \R^2$ be convex, centrally symmetric around $(0;0)$ and of area strictly bigger than $4$, then it exists $x\in A\bigcap \Z^2$ and $x\neq 0$.
\end{theorem}
\begin{proof}
    Consider $\frac{1}{2}A=\{\frac{x}{2}\vert x\in A\}$, now the area is divided by 4 (easily seen on squares and then apply the approximation of an aera by the sum of multiples squares). Now as the Area is bigger than 1 hence by the theorem $\eqref{Th:mink1}$ it exists $a'\neq b'\in \frac{1}{2}A$ such that $a'.b'\in\Z^2$. It follows that for $a=2a'\in A$ and $b=2b'\in A$ we have $$\frac{a}{2}-\frac{b}{2}\in \Z^2\iff \frac{a}{2}+\frac{-b}{2}\in \Z^2 $$ 
    As A is centrally symmetric $-b\in A$ hence by convexity of $A$ it follows that $\frac{a}{2}+\frac{-b}{2}\in A$, so we found our point in $\Z^2\bigcap A$.
\end{proof}
\begin{corollary}
    Let $\bigtriangleup abc$ be a triangle in $\R^2$ with vertices $a,b,c\in \Z^2$ such that $\bigtriangleup abc\bigcap\Z^2=\{a,b,c\}$ then the area of $\bigtriangleup abc$ is equal to $\frac{1}{2}$.
\end{corollary}
\begin{proof}
    First notice that the area of $\bigtriangleup abc$ is bigger or equal than $\frac{1}{2}$. Now without lost of generalities let one the vertices of $\bigtriangleup abc$ be $(0;0)$. Now we make the construction as illustrated in ... . We now have a parallelogram $P$ which area is $8x$ where $x$ is area of $\bigtriangleup abc$ and by construction the only points in $\Z^2$ are the red ones. Now let's shrink the parallelogram by $\epsilon$ in order to have only $(0;0)$ in $\Z^2\bigcap P$. As $P$ is convex and centrally centered, we have by $\eqref{th:mink2}$ that $$8x-\epsilon< 4\implies x<\frac{1}{2} +\frac{\epsilon}{8}$$
    Knowing by construction that this if true for any $\epsilon>0$ we have that $x=\frac{1}{2}$
\end{proof}
\begin{theorem}[Pick's theorem]
    Let $A\subseteq \R^2$ be a polygon with vertices in $\Z^2$, let $x=\vert int(A)\bigcap \Z^2\vert$ and $y=\vert \partial A\bigcap \Z^2\vert$ then the area of $A$ is equal to $x+\frac{y}{2}-1$
\end{theorem}

\begin{theorem}
    Let $p$ be a prime such that $p\equiv 1\mod 4$ then it exists $a,b\in\Z$ such that $p=a^2+b^2$.
\end{theorem}
\begin{proof}
    First we will prove that if $p\equiv 1\mod 4$ then it exists $a$ such that $a^2\equiv -1 \mod p$.\\
    To do this we first notice that $(p-1)!\equiv (-1)\mod P$. Now 
    we know that in $(p-1)!$ we have $x$ and $-x$ forall $x\in (\Z/p\Z)^{\times}$, hence $$(-1)\mod P\equiv(p-1)!\equiv (-x_1^2)\cdot(-x_2^2)\cdots(-x^2_{\frac{p-1}{2}})\equiv (-1)^{\frac{p-1}{2}}\cdot(\emph{square})=1\cdot a^2$$
    Now consider the set $A=\{(x,y)\in\R^2\vert(px+ay)^2+y^2<2p\}$, this is the formula of a circle after a linear transformation $T$ hence it is an elips. By definition $T=\begin{pmatrix}
        p & a  \\
        0 & 1  
      \end{pmatrix} $ hence $\det(T)=p$.\\
      Let $T(A)=B=\{(x,y)\in\R^2\vert x^2+y^2<2p\}$ then as $B$ represent a circle of radius $\sqrt{2p}$ the area of $B$ is equal t0 $2\pi p$ hence the area of $A$ is equal to $\frac{Area(B)}{\det(T)}=2\pi$.\\
      As $A$ is symmetrically centered, convex with an area bigger than 4, by theorem $\eqref{th:mink2}$ it exists $(x,y)\in A\bigcap\Z^2$, it satisfies $0<(px+ay)^2+y^2<2p$.
      We have $$(px+ay)^2+y^2<2p=p^2x^2+2paxy+(a^2+1)y^2\equiv0\mod p$$ it then means that it is divisible by $p$ and as $0<(px+ay)^2+y^2<2p$ it follows that $(px+ay)^2+y^2=p$.
\end{proof}
\subsection*{27 October 2023}
\begin{theorem}[Dirichlet]
    Let $\alpha_1,\dots,\alpha_n\in\R$, $Q\in\N_+$. Then there exists $(q,p_1,\dots,p_n)\in\N_+\times\Z^n$ such that
    \begin{enumerate}[i)]
        \item $1\leq q\leq Q^n$ and
        \item $\vert q\cdot\alpha_i-p_i\vert\leq \frac{1}{Q}$ for $i=1,\dots,n$
    \end{enumerate}
\end{theorem}
\begin{proof}
    Let's take the interval $[0,1)=[0,\frac{Q}{Q})$, we partition it in the following way $[0,\frac{1}{Q}),[\frac{1}{Q},\frac{2}{Q}),\dots [\frac{Q-1}{Q},1)$ and we numerate them from one to 1 to $Q$. Notice that $\forall q\in \N_+$ we have $\{q\cdot\alpha_1\}\in [0,1)$ so for each $i$ we have that it exist a unique $m$ such that  $\{q\cdot\alpha_i\}\in [\frac{m}{Q},\frac{m+1}{Q})$. Hence for each $q\in\N_+$ we have that $\{q\cdot\alpha\}=\begin{pmatrix}
        \{q\cdot\alpha_1\}\\
        \{q\cdot\alpha_2\}\\
        \cdot\\
        \cdot\\
        \cdot\\
        \{q\cdot\alpha_n\}
    \end{pmatrix}$ has a pattern : $\begin{pmatrix}
        i_1\\
        i_2\\
        \cdot\\
        \cdot\\
        \cdot\\
        i_n
    \end{pmatrix}\in\{1,\dots,Q\}^n$
    So the number of different pattern is $Q^n$ and by the Pigeon Hole principle it exists $q_1>q_2\in\{0,\dots, Q^n\}$ such that the patterns of $\{q_1\cdot\alpha\},\{q_2\cdot\alpha\}$ coincide which in other terms mean that $$\vert\vert\{q_1\cdot\alpha\}-\{q_2\cdot\alpha\}\vert\vert_{\infty}<\frac{1}{Q} .$$
    Let $p_1,p_2\in\Z^n$ such that $\{q_1\cdot\alpha\}=q_1\cdot\alpha-p_1,\{q_2\cdot\alpha\}=q_2\cdot\alpha-p_2$ hence $$\vert\vert\ (q_1-q_2)\cdot\alpha-(p_1+p_2)\vert\vert_{\infty}<\frac{1}{Q}.$$
\end{proof}
\begin{theorem}
    Let $\alpha_1,\dots,\alpha_n\in\R$, $Q\in\N_+$. Then there exists $(p,q_1,\dots,q_n)\in\N_+\times\Z^n$ such that
    \begin{enumerate}[i)]
        \item $\vert q_i\vert\leq Q^{\frac{1}{n}}$ for $i=1,\dots,n$ and
        \item $\vert p+q_1\cdot\alpha_1+\dots +q_n\cdot\alpha_n \vert\leq \frac{1}{Q}$
    \end{enumerate}
\end{theorem}
\begin{proof}
    \emph{Exercise}
\end{proof}
\begin{definition}
    Let $A\in\R^{n\times n}$ be non-singular, the set $\Lambda(A)=\{A\cdot x:x\in\Z^n\}$ is the $\emph{lattice generated by A}$.
\end{definition}
\begin{theorem}
    Let $A,B\in\R^{n\times n}$ non-singular. Then $\Lambda(A)=\Lambda(B)$ \emph{if and only if} it exist $u\in\Z^{n \times n}$ with $\det(u)=\pm 1$ and $A=B\cdot u$ ($u\in\Z^{n \times n}$ with $\det(u)=\pm 1$ is called \emph{unimodular})
\end{theorem}
\begin{proof}
    Suppose $\Lambda(A)=\Lambda(B)$ it follows that it exist $u_1,u_2\in \Z^{n\times }$ such that $A=B\cdot u_1$ and $B=A\cdot u_2$. From those equalities we can deduce that $A=A\cdot u_2\cdot u_1$ hence $u_2\cdot u_1=\Id_{n\times n}$. As $\det (u_2\cdot u_1)=1$ and that $\det(u_1),\det(u_2)\in\Z$ it follows that $\det(u_1),\det(u_2)=\pm 1$.\\
    Now we suppose that $A=B\cdot u$ with $u$ unimodular then $\Lambda(A)\subseteq\Lambda (B)$ and $u^{-1}=\frac{Adj(U)}{\det(u)}\in \Z^{n\times n}$ this means that $B=A\cdot \underbrace{u^{-1}}_{\in\Z^{n\times n}}$ hence $\Lambda(B)\subseteq \Lambda(A)$.
\end{proof}
\begin{theorem}[Minkowski with lattices]
Let $C\subseteq \R^n$, convex,bounded,centrally symmetric, $A\in\R^{n \times n}$ non-singular if the $\vol(C)>2^n\cdot\det(A)$ the it exists $v\in\Lambda(A)\backslash\{0\}$ with $v\in C$
\end{theorem}
\begin{proof}
    Let $v$ be a lattice points, in other words it exists $x\in\Z^n$ such that $v=Ax$. Then $$v\in C\iff x\in A^{-1}\cdot C= \{A^{-1}\cdot c\vert c\in C\}$$
   We know that $\vol(A^{-1}\cdot C)=\vert \det(A^{-1}\vert\cdot\vol(C)=\frac{
\vol(C)}{\det(A)}$. Therefore, as $(A^{-1}\cdot C)$ remain convex and centrally symmetric (\emph{exercise)}, by the Minkowski theorem we have that if $\vol (A^{-1}\cdot C)> 2^n$ then $(A^{-1}\cdot C)\bigcap(\Z^n\backslash\{0\}$ which is equivalent to $C\bigcap\Lambda(A)\backslash\{0\}$
\end{proof}
\begin{theorem}
    Let $A\in \R^{n\times n}$ of full rank then it exists $v\in \Lambda(A)\backslash\{0\}$ such that $$\vert\vert v\vert\vert _{\infty}\leq \det(A)^\frac{1}{n}$$
\end{theorem}
\begin{proof}
    Let $B=\{x\in \R^n:\vert\vert x\vert\vert_{\infty}\leq l\}$, then $\vol(B)=(2l)^n=2^nl^n$. If $l= \det(A)^\frac{1}{n}$ then $\vol(B)=2^n\cdot\det(\Lambda)$ hence as $B$ is convex, centrally centered and closed then, by the first theorem of minkowski, we have that it exists $v\in B\cap (\Lambda(A)\backslash \{0\}$. As $v\in B$ then $\vert\vert v\vert\vert _{\infty}\leq \det(A)^\frac{1}{n}$ 
\end{proof}
Now we prove the Dirichlet theorem with Minkowski.
\begin{proof}
    
Let $\begin{pmatrix}
    \frac{1}{Q^{n+1}}& 0& 0 &\dots& 0\\
    \alpha_1& 1&0&\dots&0\\
    \cdot&0&1&\dots&0\\
    \cdot&0&0&\dots&0\\
    \cdot&\cdot&\cdot&\dots&\cdot\\
    \alpha_n&0&0&\dots&1\\
\end{pmatrix}$
 that generates the lattice $\Lambda\subseteq\R^{n+1}$\\
 Now let $v\in\Lambda:\begin{pmatrix}
    \frac{1}{Q^{n+1}}& 0& 0 &\dots& 0\\
    \alpha_1& 1&0&\dots&0\\
    \cdot&0&1&\dots&0\\
    \cdot&0&0&\dots&0\\
    \cdot&\cdot&\cdot&\dots&\cdot\\
    \alpha_n&0&0&\dots&1\\
\end{pmatrix}\begin{pmatrix}
    q\\
    -p_1\\
    \cdot\\
    \cdot\\
    \cdot\\
    -p_n
\end{pmatrix}=\begin{pmatrix}
    \frac{q}{Q^{n+1}}\\
    q\alpha_1-p_1\\
    \cdot\\
    \cdot\\
    \cdot\\
    q\alpha_n-p_n
\end{pmatrix}$
Hence by the thm ... we can find $(q,p_1,\dots,p_n)\neq 0$ such that $\vert\vert v\vert\vert_{\infty}\leq(\frac{1}{Q^{n+1}})^{\frac{1}{n}}=\frac{1}{Q}\iff \frac{q}{Q^{n+1}}\leq \frac{1}{Q} \text{and } \vert q\alpha_i-p_i\vert\leq \frac{1}{Q} \;\forall i\in\{1,\dots,n\}$ and $q\neq 0$ otherwise the $p_i$s would be $0$ too and $(q,p_1,\dots,p_n)\neq 0$
\end{proof}



\subsection*{3 November 2023}

\begin{definition}[successive minima of a lattice $\Lambda$]
    Let $\Lambda\subseteq \R^n$ a lattice, then $\lambda_i$ is the \emph{$i$-th successive minima of $\Lambda
    $} if $B(0,\lambda_i)$ contains $i$ vectors linearly independent of $\Lambda$.
\end{definition}
\emph{Remark:} $\lambda_1$ is the length of the shortest vector of $\Lambda$. We note it $\lambda_1=SV(\Lambda)$
\begin{theorem}
    Let $\Lambda\subseteq \R^n$ a lattice, $\lambda_1,\dots,\lambda_n\in\R_{>0}$ the successive minima of $\Lambda$. Then $\lambda_1,\dots,\lambda_n\leq 2^\frac{n}{2}\cdot\det(\Lambda)$ which is equivalent to  $(\lambda_1,\cdots,\lambda_n)^{\frac{1}{n}}\leq \sqrt{n}\cdot(\det(\Lambda))^{\frac{1}{n}}$
\end{theorem}
\begin{proof}
    Let $b_1,\dots,b_n\in\Lambda$ be linearly independents where $\lambda_1,\dots,\lambda_n$ are attained, in other words $\vert\vert b_i\vert\vert_2=\lambda_i$.
    Let $b_1*,\dots b_n*$ the Gram-Schmidt orthogonalisation of the vectors $b_1,\dots,b_n$. We now then that all $x\in\R^n$ can be written as $$x=\sum y_i\cdot \frac{b_i*}{\vert\vert b_i*\vert\vert_2},\; \text{and } \vert\vert x\vert\vert_2=\vert\vert y\vert\vert_2$$
    Now we construct $\epsilon=\{\sum_i^n y_i\cdot \frac{b_i*}{\vert\vert b_i*\vert\vert}:\vert\vert\sum_i^n y_i\cdot \frac{b_i*}{\lambda_i\vert\vert b_i*\vert\vert}\vert\vert_2\leq 1, y\in\R^n\}$
    \emph{Exercise} $\vol(\epsilon)=\lambda_1\cdots\lambda_n\cdot\vol(B(0,1))$
    \begin{claim}
        $\partial\epsilon\cap\Lambda=\{0\}$
    \end{claim}
    If the claim is true then as $\epsilon$ is convex, centrally symmetric and borné then by The first theorem of Minkowski for lattices: $$\vol(\epsilon)\leq 2^n\cdot\det(\lambda)\iff \lambda_1\cdots\lambda_n\cdot\vol(B(0,1))\leq 2^n\cdot\det(\Lambda)$$

    So now we show the claim: Let $u\in\Lambda\backslash\{0\}$, we want to show that if it exists $y\in\R^n$ such that $u=\sum_i^n y_i\cdot \frac{b_i*}{\vert\vert b_i*\vert\vert}$ then $\vert\vert\sum_i^n y_i\cdot \frac{b_i*}{\lambda_i\vert\vert b_i*\vert\vert}\vert\vert_2\geq 1$.
    Let $i\in\{1,\dots,n\}$ such that $\lambda_i\leq \vert\vert u\vert\vert<\lambda_{i+1}$ then if $u=\sum_i^n y_i\cdot \frac{b_i*}{\vert\vert b_i*\vert\vert}$ then $y_{i+1}=\dots=y_n=0$ bcs otherwise $u$ would be linearly independent of the first $b_i$s terms hence $\lambda_{i+1}=\vert\vert u\vert\vert_2$.\\
    Now we look at $\vert\vert\sum_j^i y_i\cdot \frac{b_j*}{\lambda_j\vert\vert b_j*\vert\vert}\vert\vert_2\geq\frac{1}{\lambda_i}\vert\vert\sum_i^n y_i\cdot \frac{b_i*}{\lambda_i\vert\vert b_i*\vert\vert}\vert\vert_2=\frac{\vert\vert u\vert\vert}{\lambda_i}\geq 1$
\end{proof}

\subsection*{10 November 2023}
The Goal of today is to give an algorithm that: Given $A\in \Q^{n\times n}$ and non singular. Finds $v\in \Lambda(A)$ such that $\vert\vert v\vert\vert_2\leq 2^{\frac{n-1}{2}}\cdot SV(\Lambda)$.\\\\
\emph{Remark:} $\lfloor2^{\frac{n+1}{2}}\rfloor$ is a number using at most $n$ bits, hence the algorithm is in polynomial bit length regarding the input of length basis.\\\\
\emph{Recall on Gram-Schmidt orthogonalisation (GSO):}\\
Given $b_1,\dots,b_n\in \R^n$ then GSO compute $b_1^*,\dots,b_n^*$ such that \begin{enumerate}[i)]
    \item $\langle b_i^*,b_j^*\rangle=0 \; i\neq j$
    \item $ span \{b_1,\dots,b_j\}=span\{b_1^*,\dots,b_j^*\}\; \forall j\in\{1,\dots,n\}$
\end{enumerate}
First we let $b_1^*=b_1$.\\
Secondly we suppose that $b_j^^*$ for $j\in\{1,\dots,i\}$ are already found. Hence we have $b_{i+1}^*=b_{i+1}-\sum_{j=1}^i\mu_{ji}b_j^*$, moreover we have the condition \begin{align*}
    \langle b_{i+1}^*,b^*_j\rangle=0 \; for\; j=1,\dots,i&\iff \langle b_{i+1}-\sum_{j=1}^i\mu_{ji}b_j,b_j^*\rangle=0\\
    &\iff \langle b_{i+1},b_j^*\rangle-\mu_{ji}\langle b_j^*,b_j^*\rangle=0\\
    &\iff \mu_{ji}=\frac{\langle b_{i+1},b_j^*\rangle}{\langle b_j^*,b_j^*\rangle}
\end{align*}
Now in matrix let $B=[b_1,\dots,b_n]=[b_1^*,\dots,b_n^*]$
$\underbrace{\begin{pmatrix}
    1 & \mu_{1,2} & \cdots & \cdots & \mu_{1,n} \\
    0 & 1 & \mu_{2,3} & \cdots & \mu_{2,n} \\
    \vdots & \ddots & \ddots & &  \vdots \\
     \vdots & & \ddots& 1 & \mu_{n-1, n} \\
    0 & \cdots & \cdots & 0 & 1
\end{pmatrix}}_{M(\mu_{ji})}$\\
Our goal now is to find $x\in\Z^n\backslash\{0\}$ such that $\vert\vert B\cdot x\vert\vert_2$ is minimal.\\
\begin{lemma}
    The $SV(\Lambda(B))\geq \underset{i}{min} \norm{b_i^*}$ where $B=B^*M_{\mu_{ji}}$ is the GSO of $B$
\end{lemma}
\begin{proof}
    Let $x\in\Z^n\backslash\{0\}$, we have $B\cdot x=B^*\cdot M_{\mu_{ji}}\cdot \begin{pmatrix}
        x_1\\
        \vdots\\
        x_n
    \end{pmatrix}$. Moreover we have $$M_{\mu_{ji}}\cdot\begin{pmatrix}
        x_1\\
        \vdots\\
        x_k\\
        0\\
        \vdots\\
        0
    \end{pmatrix}=\begin{pmatrix}
    1 & \mu_{1,2} & \cdots & \cdots & \mu_{1,n} \\
    0 & 1 & \mu_{2,3} & \cdots & \mu_{2,n} \\
    \vdots & \ddots & \ddots & &  \vdots \\
     \vdots & & \ddots& 1 & \mu_{n-1, n} \\
    0 & \cdots & \cdots & 0 & 1
\end{pmatrix}\begin{pmatrix}
        x_1\\
        \vdots\\
        x_k\\
        0\\
        \vdots\\
        0
    \end{pmatrix}=\begin{pmatrix}
        \alpha_1\\
        \vdots\\
        x_k\\
        0\\
        \vdots\\
        0
    \end{pmatrix}$$
Hence we obtain that $B\cdot \begin{pmatrix}
        x_1\\
        \vdots\\
        x_k\\
        0\\
        \vdots\\
        0
    \end{pmatrix}= B^*\begin{pmatrix}
        \alpha_1\\
        \vdots\\
        x_k\\
        0\\
        \vdots\\
        0
    \end{pmatrix} $ and as the cells of $B^*$ are orthogonal we obtain that \begin{align*}
        \norm{B\cdot x}^2&=\norm{b_1^*\cdot\alpha_1+\dots+b_{k-1}^*\cdot\alpha_{k-1}+b_k^*\cdot x_k}^2\\
        &=\alpha_1^2\norm {b_1^*}^2+\dots +\alpha_{k-1}\norm{b_{k-1}^*}^2+\underbrace{x_k^2}_{\geq 1}\norm{b_k^*}^2\\
        &\geq \norm{b_k^*}^2
    \end{align*}
As this is true for any $x\in\Z\backslash\{0\}$ we obtain the wanted result.
\end{proof}
\emph{Definition:} Let $B\in\R^{n\times n}$ non-singular and $B=B^*\cdot M(\mu_{ji})$ be its GSO then $B$ is \emph{LLL-reduced} is \begin{enumerate}[i)]
    \item $\vert\mu_{ji}\vert\leq \frac{1}{2}$ for all $i>j$
    \item $\norm{b_i^*}^2\leq 2\norm{b_{i+1}}^2\; i=1,\dots,n-1$
\end{enumerate}
\emph{The LLL Algorithm}\begin{enumerate}
    \item Normalize $B$ ($\vert\mu_{ji}\vert\leq \frac{1}{2}$)
    \item While $B$ is not LLL-reduced\begin{enumerate}
        \item Let $i\in\{1,\dots,n-1\}$ such that $\norm{b_i^*}^2>2\cdot \norm{b_{i+1}^*}$
        \item Swap collumns $i$ and $i+1$ in $B$
        \item Normalize
    \end{enumerate}
\end{enumerate}
The idea of normalizing is simply to subtract a integer multiple of a column $i$ to a column $j$.\\
\emph{Remark:} This action is a unimodular transformation \\
\emph{Exercise} Give the unimodular Map $U\in\Z^{n\times n}$ representing this transformation.\\
\begin{lemma}
    Let $U\in\R^{n\times n}$ non-singular then $U^*$ such that $U=U^*\cdot M(\mu_{ji})$ where the columns of $U^*$ are orthogonal is unique 
\end{lemma}
\begin{proof}
    Exercise
\end{proof}
This lemma implies that when we do the normalization part we stay in a GSO of $B\cdot U_1\cdots U_m$.\\
We are now going to study the impact of the swap of two consecutive column of $B$ on the GSO. Let $(b_1,\dots b_i,b_{i+1},\dots,b_n)$ the columns of $B$ and $(b_1^*\dots b_i^*,b_{i+1}^*,\dots,b_n^*)$ the colums of the GSO of $B$. Now let $(b_1,\dots b_{i+1},b_{i},\dots,b_n)$ be the columns of $B'$ hence by construction of the GSO we have that the columns of $B'^*$ are $(b_1^*,\dots c_i^*,c_{i+1}^*,b_{i+2}^*\dots,b_n^*)$. Now by construction we know that $b_{i+1}^*=b_{i+1}-\sum_{j=1}^i\mu_{ji}b_j^*$ hence by construction of the GSO it follows that $c_i^*=b_{i+1}^*+\mu_{i+1,i}b_i^*$ which implies that $\norm{c_i^*}=\norm {b_{i+1}^*}+\norm{b_i^*}\mu_{i+1,i}^2$.\\ Therefore if the basis $(b_1,\dots b_i,b_{i+1},\dots,b_n)$ was normalized we know that $\vert\mu_{i,i+1}\vert\leq \frac{1}{2}$ and $\norm{b_i^*}^2> 2\norm{b_{i+1}}^2$, hence from the last equality we obtain that $\norm{c_i^*}^2<\frac{1}{2}\norm{b_i^*}^2+\frac{1}{4}\norm{b_i^*}^2=\frac{3}{4}\norm{b_i^*}^2$.\\
\begin{theorem}
    The LLL-Algorithm terminates.
\end{theorem}
\emph{Definition}\\
We call the \emph{potential of a matrix $B$}: $\Phi(B)=\Pi^n_{i=1} \det(B^{(i)\top}\cdot B^{(i)})$ where $B^{(i)}=[b_1,\dots,b_i]\in\Z^{n\times i}$
\begin{proof}
    Assumption: $B\in\Z^{n\times n}$. Clearly $\Phi(B)\in\N_+$.\\
    Now by definition $B^{(i)}=[b_1^*,\dots,b_n^*](M_{\mu_{jk}})_i$ where $(M_{\mu_{jk}})_i$ stand for the $i$-th firsts column $M_{\mu_{jk}}$\\
    \emph{Exercise :} Show that $\det(B^{(i)\top}\cdot B^{(i)})=\Pi^i_{j=1}\norm{b_i^*}^2$\\
    From this results it follows that $$\Phi(B)=\Pi_{i=1}^n\norm{b_1^*}^{2n}\cdots\norm{b_n^*}^2$$
    Now we can compare $\Phi(B)$ and $\Phi(B')$ where $B'$ is the matrix with the swap of two columns.
    $$\frac{\Phi(B)}{\Phi(B')}=\frac{\norm{b_i^*}^{2(n-i+1)}\cdot\norm{b_{i+1}^*}^{2(n-i)}}{\norm{c_i^*}^{2(n-i+1)}\cdot\norm{c_{i+1}^*}^{2(n-i)}}$$
    \emph{Exercise:} Show that $\norm{c_i^*}\cdot\norm{c_{i+1}^*}=\norm{b_i^*}\cdot\norm{b_{i+1}^*}$\\
    We now have $\frac{\phi(B)}{\phi(B')}=\frac{\norm{b_i^*}^2}{\norm{c_i^*}^2}>\frac{\norm{b_i^*}^2}{\frac{3}{4}\norm{b_i^*}^2}=\frac{4}{3}$.\\
    Where the inequality comes from ...
    It follows that $\Phi(B')<\frac{3}{4}\Phi(B)$. As $\Phi(B')$ is an integer bigger or equal than 1 for any step of the algoritm and that $\Phi(B')$ decrease at each step the algorithm has to stop. 
\end{proof}

\bibliographystyle{plain}
\bibliography{references}
\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:

